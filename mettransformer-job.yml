apiVersion: batch/v1
kind: Job
metadata:
  name: mettransformer
spec:
  template:
    spec:
      containers:
      - name: gpu-container
        image: gitlab-registry.nrp-nautilus.io/simon.poon/transformer_met:latest
        command:
        - "/bin/bash"
        - "-c"
        - " git clone https://github.com/simon-poon/Transformer_MET.git &&
            cd Transformer_MET &&
            weaver \
            --data-train "/mettransformervol/perfNano_TTbar_PU200.110X/perfNano_TTbar_PU200.110X_set2.root" \
            "/mettransformervol/perfNano_TTbar_PU200.110X_set3.root" \
            "/mettransformervol/perfNano_TTbar_PU200.110X_set4.root" \
            "/mettransformervol/perfNano_TTbar_PU200.110X_set5.root" \
            "/mettransformervol/perfNano_TTbar_PU200.110X_set6.root" \
            --data-val "/mettransformervol/perfNano_TTbar_PU200.110X/perfNano_TTbar_PU200.110X_set0.root" \
            --data-test "/mettransformervol/perfNano_TTbar_PU200.110X/perfNano_TTbar_PU200.110X_set1.root" \
            --data-config data/JetClass/JetClass_full.yaml --network-config example_ParticleTransformer.py --use-amp \
            --model-prefix /mettransformervol/saved_models/mettransformer-test/ \
            --num-workers 2 --fetch-step 0.01 \
            --batch-size 256 --start-lr 1e-3 \
            --num-epochs 1 --gpus 0 \
            --optimizer adam --log /mettransformervol/logs/metttransformer-test.log --predict-output pred.root \
            --tensorboard JetClass_Pythia_full_ParT \
            --regression-mode"
        volumeMounts:
        - mountPath: /mettransformervol
          name: mettransformervol
        resources:
          limits:
            memory: 50Gi
            cpu: "10"
            nvidia.com/gpu: "1"
          requests:
            memory: 20Gi
            cpu: "10"
            nvidia.com/gpu: "1"
      volumes:
      - name: mettransformervol
        persistentVolumeClaim:
          claimName: mettransformervol

      restartPolicy: Never
  backoffLimit: 0
